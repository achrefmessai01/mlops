services:
  # Application MLOps
  mlops-app:
    build: 
      context: ./app
      dockerfile: Dockerfile
    container_name: mlops-app-main
    ports:
      - "8000:8000"
    environment:
      # Configuration des mod√®les IA
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      
      # Configuration PostgreSQL
      - POSTGRES_DB=mlops
      - POSTGRES_USER=mlops
      - POSTGRES_PASSWORD=mlops123
      - POSTGRES_HOST=postgres-main
      - POSTGRES_PORT=5432
      
      # Configuration Redis
      - REDIS_HOST=redis-cache
      - REDIS_PORT=6379
      
      # Configuration de base
      - PYTHONPATH=/app
      - LOG_LEVEL=INFO
      
      # Configuration pour LLM Judge System
      - JUDGE_MODEL=gpt-4o-mini
      - JUDGE_ANALYSIS_ENABLED=true
      - JUDGE_AUTO_ANALYSIS_HOURS=24
      
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./exports:/app/exports
      - ./judge_analysis:/app/judge_analysis
      - ./static:/app/static
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      redis-cache:
        condition: service_healthy
      postgres-main:
        condition: service_healthy
    networks:
      - mlops-network

  # Judge Scheduler Service
  judge-scheduler:
    build: 
      context: ./app
      dockerfile: Dockerfile
    container_name: judge-scheduler-service
    environment:
      # Same configuration as mlops-app
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - POSTGRES_DB=mlops
      - POSTGRES_USER=mlops
      - POSTGRES_PASSWORD=mlops123
      - POSTGRES_HOST=postgres-main
      - POSTGRES_PORT=5432
      - PYTHONPATH=/app
      - LOG_LEVEL=INFO
      - JUDGE_MODEL=gpt-4o-mini
      - JUDGE_SCHEDULER_ENABLED=true
      - JUDGE_ANALYSIS_INTERVAL=3600
      - JUDGE_AUTO_ANALYSIS_HOURS=24
    volumes:
      - ./logs:/app/logs
      - ./judge_analysis:/app/judge_analysis
    restart: unless-stopped
    command: ["python", "judge_scheduler.py"]
    depends_on:
      mlops-app:
        condition: service_healthy
      postgres-main:
        condition: service_healthy
    networks:
      - mlops-network

  # Main PostgreSQL Database
  postgres-main:
    image: postgres:15-alpine
    container_name: postgres-mlops-main
    environment:
      - POSTGRES_DB=mlops
      - POSTGRES_USER=mlops
      - POSTGRES_PASSWORD=mlops123
    volumes:
      - postgres_main_data:/var/lib/postgresql/data
      - ./database/postgres/postgres_init.sql:/docker-entrypoint-initdb.d/01-postgres_init.sql:ro
    ports:
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mlops -d mlops"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - mlops-network

  # Redis Cache
  redis-cache:
    image: redis:7-alpine
    container_name: redis-mlops-cache
    ports:
      - "6379:6379"
    volumes:
      - redis_cache_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - mlops-network

  # Prometheus Monitoring
  prometheus-monitor:
    image: prom/prometheus:latest
    container_name: prometheus-monitoring
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_monitor_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--enable-feature=exemplar-storage'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      mlops-app:
        condition: service_healthy
    networks:
      - mlops-network

  # Grafana Visualization
  grafana-dashboard:
    image: grafana/grafana:latest
    container_name: grafana-visualization
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_SECURITY_ADMIN_USER=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/etc/grafana/provisioned-dashboards/mlops-dashboard.json
    volumes:
      - grafana_dashboard_data:/var/lib/grafana
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/dashboard-definitions:/etc/grafana/provisioned-dashboards:ro
    restart: unless-stopped
    depends_on:
      prometheus-monitor:
        condition: service_healthy
    networks:
      - mlops-network

  # Nginx Reverse Proxy
  nginx-proxy:
    image: nginx:alpine
    container_name: nginx-reverse-proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./monitoring/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    restart: unless-stopped
    depends_on:
      mlops-app:
        condition: service_healthy
      grafana-dashboard:
        condition: service_started
    networks:
      - mlops-network

volumes:
  redis_cache_data:
  postgres_main_data:
  prometheus_monitor_data:
  grafana_dashboard_data:
  judge_analysis_data:

networks:
  mlops-network:
    driver: bridge